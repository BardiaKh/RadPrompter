{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from radprompter import RadPrompter, Prompt, vLLMClient, OllamaClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_files = glob.glob(\"sample_reports/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "report_ids = []\n",
    "for report_file in report_files:\n",
    "    report_ids.append(os.path.basename(report_file))\n",
    "    with open(report_file, 'r') as f:\n",
    "        reports.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = Prompt('demo_prompt_no_CoT.toml')\n",
    "prompt = Prompt('sample_prompt.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='padding: 0; border-radius: 5px; font-family: Arial; line-height: 1.2rem; border: 1px solid currentColor'><div style='display: flex; align-items: top; padding: 0; border-right-width: 1px'><h4 style='margin: 0; padding: 8px; flex: 0 0 100px; '>System:</h4><p style='margin: 0; padding: 8px; border-left: 1px solid currentColor;'>You are a helpful assistant that has 20 years of experience in reading radiology reports and extracting data elements.</p></div><div style='display: flex; align-items: top; padding: 0;'><h4 style='margin: 0; padding: 8px; flex: 0 0 100px;'>User:</h4><p style='margin: 0; padding: 8px; flex-grow: 1; border-left: 1px solid currentColor;border-top: 1px solid currentColor;'>Carefully review the provided chest CT report (in the &lt;report&gt; tag). Ensure that each data element is accurately captured.<br><br>Here is the report:<br>&lt;report&gt;<br><span style='background-color: rgb(255, 224, 178, 0.3);'>{{report}}</span><br>&lt;/report&gt;<br><br>Please pay attention to the following details:<br>- Your attention to detail is crucial for maintaining the integrity of the medical records. <br>- You should not confabulate information, and if something is not mentioned, you should assume that it is `Absent` unless otherwise stated.<br>- The report may contain additional information that is not relevant to the requested data elements. Please ignore that information.<br>- We are interested at findings at the time of scan, not the previous ones, so only consider the impression and findings sections of the report.<br>- Do not print anything else other than the provided output format.<br>I want you to extract the following data element from the report:<br><span style='background-color: rgb(255, 224, 178, 0.3);'>{{hint}}</span><br><br>After you provide the data element, I will ask you to provide an explanation and then the final answer.<br><br>Now give your initial answer. Then provide a step-by-step explanation based on the information in the report, using no more than three short sentences. You can use less sentences if needed.Try to critically appraise your initial answer, which MIGHT be wrong. Then give me your final answer. Format your answers with this format as:<br><br>&lt;answer&gt;<br>&lt;initial_answer&gt;<br>initial answer goes here<br>&lt;/initial_answer&gt;<br>&lt;explanation&gt;<br>1. your first explanation goes here<br>2. your second explanation goes here (if needed)<br>3. your third explanation goes here (if needed)<br>&lt;/explanation&gt;<br>&lt;final_answer&gt;<br>final answer goes here<br>&lt;/final_answer&gt;<br>&lt;/answer&gt;<br></p></div><div style='display: flex; align-items: top; padding: 0;'><h4 style='margin: 0; padding: 8px; flex: 0 0 100px;'>Assistant:</h4><p style='margin: 0; padding: 8px; flex-grow: 1; border-left: 1px solid currentColor;border-top: 1px solid currentColor;'>&lt;answer&gt;<br>&lt;initial_answer&gt;<span style='background-color: rgb(178, 219, 255, 0.3);'>[... response ...]</span>&lt;/answer&gt;</p></div><div style='display: flex; align-items: top; padding: 0;'><h4 style='margin: 0; padding: 8px; flex: 0 0 100px;'>User:</h4><p style='margin: 0; padding: 8px; flex-grow: 1; border-left: 1px solid currentColor;border-top: 1px solid currentColor;'>Now, based on your expalanation, provide your final answer elements in a valid JSON format and is between &lt;json&gt; and &lt;/json&gt; tags:<br><br>&lt;json&gt;<br>{<br>  &quot;<span style='background-color: rgb(255, 224, 178, 0.3);'>{{variable_name}}</span>&quot;: &quot;answer&quot; <br>}<br>&lt;/json&gt;<br></p></div><div style='display: flex; align-items: top; padding: 0;'><h4 style='margin: 0; padding: 8px; flex: 0 0 100px;'>Assistant:</h4><p style='margin: 0; padding: 8px; flex-grow: 1; border-left: 1px solid currentColor;border-top: 1px solid currentColor;'>&lt;json&gt;<br>{<br>  &quot;<span style='background-color: rgb(255, 224, 178, 0.3);'>{{variable_name}}</span>&quot; : &quot;<span style='background-color: rgb(178, 219, 255, 0.3);'>[... response ...]</span>&lt;/json&gt;</p></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vLLMClient(\n",
    "    model = \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    base_url = \"http://localhost:8000/v1\",\n",
    "    temperature = 0.0,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = RadPrompter(\n",
    "    client=client, \n",
    "    prompt=prompt,\n",
    "    concurrency=12,\n",
    "    hide_blocks=True,\n",
    "    output_directory=\"output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [{'report': sample_report} for sample_report in reports]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [{'report': sample_report, 'report_id': report_id} for sample_report, report_id in zip(reports, report_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 3/3 [00:04<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "results = engine(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.save_log(\"demo_no_CoT.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
