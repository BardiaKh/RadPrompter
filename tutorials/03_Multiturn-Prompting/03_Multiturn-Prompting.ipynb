{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Multi-turn Prompting\n",
    "\n",
    "In this tutorial, we'll explore RadPrompter's support for multi-turn prompting. This allows for more complex interactions with the model, where the model's output from one turn can inform the prompt for the next turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "If you don't have `RadPrompter` installed, you can install it using pip:\n",
    "\n",
    "```bash\n",
    "pip install radprompter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "\n",
    "As usual, we start by importing the `Prompt` class and loading our TOML file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METADATA]\n",
      "version = 0.1\n",
      "description = \"A sample prompt for RadPrompter\"\n",
      "\n",
      "[PROMPTS]\n",
      "system_prompt = \"You are a helpful assistant that has 20 years of experience in reading radiology reports and extracting data elements.\"\n",
      "\n",
      "user_prompt_intro = \"\"\"\n",
      "Carefully review the provided chest CT report (in the <report> tag). Ensure that each data element is accurately captured. Here is the report:\n",
      "<report>\n",
      "{{report}}\n",
      "</report>\n",
      "\"\"\"\n",
      "\n",
      "user_prompt_cot = \"\"\"\n",
      "I want you to extract the following data element from the report: 'Pulmonary Embolism'\n",
      "Here are your options and you can explicitly use one of these:\n",
      "  - `Present`\n",
      "  - `Absent`\n",
      "Hint: \"Indicate `Present` if the report explicitly mentions the patient has pulmonary embolism in their CT scan. Indicate `Absent` if pulmonary embolism is not seen or if a previously observed pulmonary embolism is mentioned as resolved.\n",
      "After you provide the data element, I will ask you to provide an explanation and then the final answer.\n",
      "Now give your initial answer. Then provide a step-by-step explanation based on the information in the report, using no more than three short sentences. You can use less sentences if needed.Try to critically appraise your initial answer, which MIGHT be wrong. Then give me your final answer.\n",
      "Format your answers with this format as:\n",
      "<answer>\n",
      "<initial_answer>\n",
      "initial answer goes here\n",
      "</initial_answer>\n",
      "<explanation>\n",
      "1. your first explanation goes here\n",
      "2. your second explanation goes here (if needed)\n",
      "3. your third explanation goes here (if needed) \n",
      "</explanation>\n",
      "<final_answer>\n",
      "final answer goes here\n",
      "</final_answer>\n",
      "</answer>\n",
      "\"\"\"\n",
      "\n",
      "user_prompt_format = \"\"\"\n",
      "Great. Now please format your response in JSON format like this:\n",
      "{\n",
      "    \"answer\": \"your final answer\"\n",
      "}\n",
      "\"\"\"\n",
      "\n",
      "[CONSTRUCTOR]\n",
      "system = \"rdp(system_prompt)\"\n",
      "user = [\"rdp(user_prompt_intro + user_prompt_cot)\", \"rdp(user_prompt_format)\"]\n",
      "stop_tags = [\"</answer>\", \"}\"]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./03_Multiturn-Prompting.toml\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "print(\"\".join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this TOML file, we've defined our prompt components in the `[PROMPTS]` section as before. The key difference is in the `[CONSTRUCTOR]` section:\n",
    "\n",
    "```toml\n",
    "[CONSTRUCTOR]\n",
    "system = \"rdp(system_prompt)\"\n",
    "user = [\"rdp(user_prompt_intro + user_prompt_cot)\", \"rdp(user_prompt_format)\"]\n",
    "stop_tags = [\"</answer>\", \"}\"]\n",
    "```\n",
    "\n",
    "Instead of a single user prompt, we now have a list of two prompts. The first prompt asks the model to extract a data element from the report and provide an explanation, just like in the previous tutorial. The second prompt then asks the model to format its response as JSON.\n",
    "\n",
    "We've also updated the `stop_tags` to include both the `</answer>` tag from the first prompt and the `}` character that will end the JSON object in the second prompt.\n",
    "\n",
    "Let's create our prompt object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='padding: 0; border-radius: 5px; font-family: Arial; line-height: 1.2rem; border: 1px solid currentColor'><div style='display: flex; align-items: top; padding: 0; border-right-width: 1px'><h4 style='margin: 0; padding: 8px; flex: 0 0 100px; '>System:</h4><p style='margin: 0; padding: 8px; border-left: 1px solid currentColor;'>You are a helpful assistant that has 20 years of experience in reading radiology reports and extracting data elements.</p></div><div style='display: flex; align-items: top; padding: 0;'><h4 style='margin: 0; padding: 8px; flex: 0 0 100px;'>User:</h4><p style='margin: 0; padding: 8px; flex-grow: 1; border-left: 1px solid currentColor;border-top: 1px solid currentColor;'>Carefully review the provided chest CT report (in the &lt;report&gt; tag). Ensure that each data element is accurately captured. Here is the report:<br>&lt;report&gt;<br><span style='background-color: rgb(255, 224, 178, 0.3);'>{{report}}</span><br>&lt;/report&gt;<br>I want you to extract the following data element from the report: &#x27;Pulmonary Embolism&#x27;<br>Here are your options and you can explicitly use one of these:<br>  - `Present`<br>  - `Absent`<br>Hint: &quot;Indicate `Present` if the report explicitly mentions the patient has pulmonary embolism in their CT scan. Indicate `Absent` if pulmonary embolism is not seen or if a previously observed pulmonary embolism is mentioned as resolved.<br>After you provide the data element, I will ask you to provide an explanation and then the final answer.<br>Now give your initial answer. Then provide a step-by-step explanation based on the information in the report, using no more than three short sentences. You can use less sentences if needed.Try to critically appraise your initial answer, which MIGHT be wrong. Then give me your final answer.<br>Format your answers with this format as:<br>&lt;answer&gt;<br>&lt;initial_answer&gt;<br>initial answer goes here<br>&lt;/initial_answer&gt;<br>&lt;explanation&gt;<br>1. your first explanation goes here<br>2. your second explanation goes here (if needed)<br>3. your third explanation goes here (if needed) <br>&lt;/explanation&gt;<br>&lt;final_answer&gt;<br>final answer goes here<br>&lt;/final_answer&gt;<br>&lt;/answer&gt;<br></p></div><div style='display: flex; align-items: top; padding: 0;'><h4 style='margin: 0; padding: 8px; flex: 0 0 100px;'>Assistant:</h4><p style='margin: 0; padding: 8px; flex-grow: 1; border-left: 1px solid currentColor;border-top: 1px solid currentColor;'><span style='background-color: rgb(178, 219, 255, 0.3);'>[... response ...]</span>&lt;/answer&gt;</p></div><div style='display: flex; align-items: top; padding: 0;'><h4 style='margin: 0; padding: 8px; flex: 0 0 100px;'>User:</h4><p style='margin: 0; padding: 8px; flex-grow: 1; border-left: 1px solid currentColor;border-top: 1px solid currentColor;'>Great. Now please format your response in JSON format like this:<br>{<br>    &quot;answer&quot;: &quot;your final answer&quot;<br>}<br></p></div><div style='display: flex; align-items: top; padding: 0;'><h4 style='margin: 0; padding: 8px; flex: 0 0 100px;'>Assistant:</h4><p style='margin: 0; padding: 8px; flex-grow: 1; border-left: 1px solid currentColor;border-top: 1px solid currentColor;'><span style='background-color: rgb(178, 219, 255, 0.3);'>[... response ...]</span>}</p></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from radprompter import Prompt\n",
    "\n",
    "prompt = Prompt(\"./03_Multiturn-Prompting.toml\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client & Engine\n",
    "\n",
    "We'll use the `vLLMClient` and `RadPrompter` engine as in previous tutorials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radprompter import RadPrompter, vLLMClient\n",
    "\n",
    "client = vLLMClient(\n",
    "    model = \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    base_url = \"http://localhost:9999/v1\",\n",
    "    temperature = 0.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "engine = RadPrompter(\n",
    "    client=client,\n",
    "    prompt=prompt, \n",
    "    output_file=\"output_tutorial_3.csv\",\n",
    "    concurrency=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run it on our sample reports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 3/3 [00:13<00:00,  4.47s/it]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "report_files = glob.glob(\"../../sample_reports/*.txt\")\n",
    "\n",
    "reports = []\n",
    "for file in report_files:\n",
    "    with open(file, \"r\") as f:\n",
    "        reports.append({\"report\": f.read(), \"file_name\": file})\n",
    "\n",
    "engine(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The engine will process each report using our multi-turn prompt and save the results to `output_tutorial_3.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default_response_0</th>\n",
       "      <th>default_response_1</th>\n",
       "      <th>report</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;answer&gt;\\n&lt;Present&lt;/Present&gt;\\n_initial_answer_...</td>\n",
       "      <td>{\\n    \"answer\": {\\n        \"data_element\": \"P...</td>\n",
       "      <td>Clinical Information:\\n72-year-old female with...</td>\n",
       "      <td>../../sample_reports/sample_report_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;answer&gt;\\n&lt;Present&gt;\\n&lt;initial_answer&gt;\\nBased o...</td>\n",
       "      <td>{\\n    \"answer\": {\\n        \"Present\",\\n      ...</td>\n",
       "      <td>Here is an example radiology report describing...</td>\n",
       "      <td>../../sample_reports/sample_report_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;answer&gt;\\n&lt;initial_answer&gt;\\nPresent\\n&lt;/initial...</td>\n",
       "      <td>{\\n    \"answer\": {\\n        \"initial_answer\": ...</td>\n",
       "      <td>Clinical Information:\\n67-year-old male with s...</td>\n",
       "      <td>../../sample_reports/sample_report_1.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      default_response_0  \\\n",
       "index                                                      \n",
       "0      <answer>\\n<Present</Present>\\n_initial_answer_...   \n",
       "1      <answer>\\n<Present>\\n<initial_answer>\\nBased o...   \n",
       "2      <answer>\\n<initial_answer>\\nPresent\\n</initial...   \n",
       "\n",
       "                                      default_response_1  \\\n",
       "index                                                      \n",
       "0      {\\n    \"answer\": {\\n        \"data_element\": \"P...   \n",
       "1      {\\n    \"answer\": {\\n        \"Present\",\\n      ...   \n",
       "2      {\\n    \"answer\": {\\n        \"initial_answer\": ...   \n",
       "\n",
       "                                                  report  \\\n",
       "index                                                      \n",
       "0      Clinical Information:\\n72-year-old female with...   \n",
       "1      Here is an example radiology report describing...   \n",
       "2      Clinical Information:\\n67-year-old male with s...   \n",
       "\n",
       "                                      file_name  \n",
       "index                                            \n",
       "0      ../../sample_reports/sample_report_2.txt  \n",
       "1      ../../sample_reports/sample_report_3.txt  \n",
       "2      ../../sample_reports/sample_report_1.txt  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"output_tutorial_3.csv\", index_col='index')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `default_response_0` and `default_response_1` columns hold the LLM response to first and second question, respectively. Please note that the `stop_tag` is not returned in the LLM response (see Tutorial 02)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadPrompter Version: 1.1.0\n",
      "Model: meta-llama/Meta-Llama-3-8B-Instruct\n",
      "Prompt TOML: /Users/bardiakhosravi/Desktop/GitHub/RadPrompter/tutorials/03_Multiturn-Prompting/03_Multiturn-Prompting.toml\n",
      "Prompt Version: 0.1\n",
      "Prompt Hash: 06f66066098813d66e786cbc2d86e6fa\n",
      "Concurrency Factor: 2\n",
      "Start Time: 2024-05-19 16:43:44\n",
      "End Time: 2024-05-19 16:43:58\n",
      "Duration: 14.0\n",
      "Number of Items: 3\n",
      "Average Processing Time: 4.666666666666667\n",
      "\n",
      "\n",
      "-------------------- *** - Prompt Content - *** --------------------\n",
      "[METADATA]\n",
      "version = 0.1\n",
      "description = \"A sample prompt for RadPrompter\"\n",
      "\n",
      "[PROMPTS]\n",
      "system_prompt = \"You are a helpful assistant that has 20 years of experience in reading radiology reports and extracting data elements.\"\n",
      "\n",
      "user_prompt_intro = \"\"\"\n",
      "Carefully review the provided chest CT report (in the <report> tag). Ensure that each data element is accurately captured. Here is the report:\n",
      "<report>\n",
      "{{report}}\n",
      "</report>\n",
      "\"\"\"\n",
      "\n",
      "user_prompt_cot = \"\"\"\n",
      "I want you to extract the following data element from the report: 'Pulmonary Embolism'\n",
      "Here are your options and you can explicitly use one of these:\n",
      "  - `Present`\n",
      "  - `Absent`\n",
      "Hint: \"Indicate `Present` if the report explicitly mentions the patient has pulmonary embolism in their CT scan. Indicate `Absent` if pulmonary embolism is not seen or if a previously observed pulmonary embolism is mentioned as resolved.\n",
      "After you provide the data element, I will ask you to provide an explanation and then the final answer.\n",
      "Now give your initial answer. Then provide a step-by-step explanation based on the information in the report, using no more than three short sentences. You can use less sentences if needed.Try to critically appraise your initial answer, which MIGHT be wrong. Then give me your final answer.\n",
      "Format your answers with this format as:\n",
      "<answer>\n",
      "<initial_answer>\n",
      "initial answer goes here\n",
      "</initial_answer>\n",
      "<explanation>\n",
      "1. your first explanation goes here\n",
      "2. your second explanation goes here (if needed)\n",
      "3. your third explanation goes here (if needed) \n",
      "</explanation>\n",
      "<final_answer>\n",
      "final answer goes here\n",
      "</final_answer>\n",
      "</answer>\n",
      "\"\"\"\n",
      "\n",
      "user_prompt_format = \"\"\"\n",
      "Great. Now please format your response in JSON format like this:\n",
      "{\n",
      "    \"answer\": \"your final answer\"\n",
      "}\n",
      "\"\"\"\n",
      "\n",
      "[CONSTRUCTOR]\n",
      "system = \"rdp(system_prompt)\"\n",
      "user = [\"rdp(user_prompt_intro + user_prompt_cot)\", \"rdp(user_prompt_format)\"]\n",
      "stop_tags = [\"</answer>\", \"}\"]\n"
     ]
    }
   ],
   "source": [
    "engine.save_log(\"log_tutorial_3.log\")\n",
    "\n",
    "with open(\"log_tutorial_3.log\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial introduces the concept of multi-turn prompting, where the `user` parameter in the `[CONSTRUCTOR]` section is a list of prompts instead of a single prompt. The model's output from each prompt is used as context for the next prompt, allowing for more complex interactions.\n",
    "\n",
    "The provided TOML file shows an example of a two-turn prompt, where the first turn asks the model to extract a data element and provide an explanation, and the second turn asks the model to format this response as JSON."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
